
1. Take the Shakespeare's collection of plays as the corpus and query the collection based on the combination of multiple keywords.
•	Use Linear Search or Brute Force or Grep Command


import nltk
from os import listdir
from os.path import isfile

nltk.download('punkt')
file_list = []

pattern = "PORTIA"

def get_files():

    for file in listdir("corpus"):

        if file.endswith(".txt"):

            file_list.append(file)


def search_pattern(file):
    
    file_content = open("corpus/" + file).read()
    tokens = nltk.word_tokenize(file_content)
    
    if pattern in tokens:
        
        return True

def scan_files():

    for file in file_list:

        if search_pattern(file):
    
            print(file)


if __name__ == '__main__':

    get_files()
    scan_files()


--------------------------------------------------------------------------------------------------------------------------------
2. Take the Shakespeare's collection of plays as the corpus and query the collection based on the combination of multiple keywords.
•	Term-Document Incidence Matrix


import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from os import listdir
from os.path import isfile

docs = [open("corpus/play1.txt").read(), open("corpus/play2.txt").read()]


vec=CountVectorizer()


X=vec.fit_transform(docs)


df=pd.DataFrame(X.toarray(), columns=vec.get_feature_names())
print(df)


-------------------------------------------------------------------------------------------------------------------------------
3. Take the Shakespeare's collection of plays as the corpus and query the collection based on the combination of multiple keywords.
•	Inverted Indexes
o	Using Arrays
o	Using Linked List as postings list


inverted_dict = {
    
    "PORTIA" :[],
    "SCENE" :[],
    "Julius":[]
}

import nltk
from os import listdir
from os.path import isfile

file_list = []

pattern_one = "PORTIA"
pattern_two = "SCENE"
pattern_three = "Julius"

pattern_one_list = []
pattern_two_list = []
pattern_three_list = []

def get_files():

    for file in listdir("corpus"):

        if file.endswith(".txt"):

            file_list.append(file)


def search_pattern(file, pattern):
    
    file_content = open("corpus/" + file).read()
    tokens = nltk.word_tokenize(file_content)
    
    if pattern in tokens:
        
        return True

def scan_files(number, pattern):

    for file in file_list:
        
        if number == 1:
            
            if search_pattern(file, pattern):pattern_one_list.append(file)
            
        elif number == 2:
                
            if search_pattern(file, pattern):pattern_two_list.append(file)
                
        elif number == 3:
                
            if search_pattern(file, pattern):pattern_three_list.append(file)


if __name__ == '__main__':

    get_files()
    scan_files(1, pattern_one)
    scan_files(2, pattern_two)
    scan_files(3, pattern_three)
    
    
    inverted_dict.update(PORTIA = pattern_one_list)
    inverted_dict.update(SCENE = pattern_two_list)
    inverted_dict.update(Julius = pattern_three_list)
    
    print(inverted_dict["PORTIA"])
    print(inverted_dict["SCENE"])
    print(inverted_dict["Julius"])
--------------------------------------------------------------------------------------------------------------------------------------
4)4. Take the Shakespeare’s collection of plays as the corpus and perform
•	Tokenization
•	Capitalization/case-folding
•	Stemming
 

import nltk

from nltk.corpus import stopwords

def search_pattern():
    
    file_content = open("D:/corpus/play1.txt").read()
    
    word_punct_tokenizer = nltk.tokenize.WordPunctTokenizer()
    
    # TOKENIZATION
    token_words = word_punct_tokenizer.tokenize(file_content)
    
    copy_token_words = token_words
    
    for token in token_words :
        
        if token in stopwords.words('english'):
            
            copy_token_words.remove(token)
            
    #print(copy_token_words)
    
    
    # CAPITALIZATION/CASE FOLDING
   
    
    
    
    #STEMMING
    
    stem = nltk.stem.PorterStemmer()
    
    copy_token_words = [stem.stem(word) for word in copy_token_words]
    #print(copy_token_words)
    
    copy_token_words = [word.capitalize() for word in copy_token_words]
    
    print(copy_token_words)
            

if __name__ == '__main__':
    
    search_pattern()